---
title: "Week 12: Model Selection"
author: "Caren Goldberg"
date: "`r Sys.Date()`"
show_toc: true
output:
  knitr:::html_vignette:
    toc: yes
    fig_width: 4 
    fig_height: 3.5
vignette: >
  %\VignetteIndexEntry{Week 12: Model Selection}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
## 1. Overview of Worked Example

### a) Goals and Background

**Goals**: The goal of this worked example is for you to become familiar with creating and analyzing landscape genetic hypotheses using maximum likelihood population effect models (MLPE; Van Strien et al. 2012) and information theory. With this approach, we focus on evaluating evidence for the influence of the (intervening) landscape on link-based metrics (i.e. genetic distance). Incorporating node-based effects (i.e. pond size, etc.) will be covered in the gravity modeling lab. 

We will re-analyze a dataset from Goldberg and Waits 2010 using a maximum likelihood population effect model (MLPE). 

### b) Data set

In previous labs, you have created genetic distance matrices, so here we are going to start with those data already complete, as are the landscape data. For MLPE, two vectors representing the nodes at the ends of each link must be created. These are already included in the data set (`pop1` and `pop2`). 

Here's a map of the study area. The lines represent those pair-wise links between sampling locations that we will be considering here (graph model: Delaunay triangulation).

![Map of study area](WE12_Fig1.png)

Each row in the file 'CSF_network.csv' represents a link between two pairs of sampling locations. The columns contain the following variables:

- **Id**: Link ID.
- **Name**: Link name (combines the two site names).
- **logDc.km**: Genetic distance per geographic distance, log transformed (response variable).
- **LENGTH**: Euclidean distance.
- **slope**: Average slope along the link.
- **solarinso**: Average solar insolation along the link.
- **soils**: Dominant soil type along the link (categorical).
- **ag**: Proportion of agriculture along the link.
- **grass**: Proportion of grassland along the link.
- **shrub**: Proportion of shrubland along the link.
- **hi**: Proportion of high density forest along the link. 
- **lo**: Proportion of low density forest along the link.
- **dev**: Proportion of development (buildings) along the link.
- **forest**: Proportion of forest (the sum of hi and lo) along the link.
- **pop1**: 'From' population.
- **pop2**: 'To' population.

### c) Required R libraries

All required packages should have been installed already when you installed 'LandGenCourse'.

```{r packages global_options, include=TRUE, results="hide", message=FALSE, warning=FALSE}
library(LandGenCourse)
library(ggplot2)
#require(lme4)
#require(usdm)
```

### d) Import data

First, read in the dataset. It is named CSF (Columbia spotted frog) to differentiate it from the RALU dataset you have used in previous labs (same species, very different landscapes). 

```{r}
CSFdata <- read.csv(system.file("extdata", "CSF_network.csv", 
                                        package = "LandGenCourse"))
head(CSFdata) 
```

Take a look at the column names and make sure you and R agree on what everything is called, and on the data types (e.g., factor vs. character).

```{r}
str(CSFdata)
```

- `Name` and `soils` are interpreted as factors,
- `Id`, `pop1` and `pop2` are vectors of integers, and
- everything else is a numeric vector, i.e., continuous variable. 

The response Y in our MLPE models will be `logDc.km`, the genetic distance per geographic distance, log transformed to meet normality assumptions. This was used in the paper as a way to include IBD as the base assumption without increasing k. The landscape variables were then also estimated so that they would  not necessarily increase with increasing distance between sites (e.g., proportion of forest between sites).

**This is a pruned network, where the links are only those neighbors in a Delauney trangulation. <Capture.PNG>**

For this exercise, you will test 5 alternative hypotheses. At the end, you will be invited to create your own hypotheses from these variables and test support for them.

## 2. Fitting candidate models

### a) Alternative hypotheses

In information theory, we evaluate evidence for a candidate set of hypotheses that we develop from the literature and theory. Although it is mathematically possible (and often practiced) to fit all possible combinations of input variables, that approach is not consistent with the methodology (see Burnham and Anderson 2002 Chapter 8, the reading for this unit, for more detail). Here, your "a priori"" set of hypotheses (as in the Week 12 Conceptual Exercise) is as follows:

1.	**Full model**: solarinso, forest, ag, shrub, dev
2.	**Landcover model**: ag, shrub, forest, and dev
3.	**Human footprint model**: ag, dev
4.	**Energy conservation model**: slope, shrub, dev
5.	**Historical model**: soils, slope, solarinso

### b) Prepare for model fitting

Because link data are not independent (i.e. the genetic diversity at node 1 influences both the node1/node2 genetic distance and that from node1/node3, etc.), we need to develop a set of random effects to account for this dependency, so that we seperate the pattern due to this covariance from the signal of landscape influence on genetic distance. We start by creating matrices from the `pop1` and `pop2` variables:

Create the `Zl` and `ZZ` matrices:

```{r}
Zl <- lapply(c("pop1","pop2"), function(nm) 
  Matrix:::fac2sparse(CSFdata[[nm]], "d", drop=FALSE))
ZZ <- Reduce("+", Zl[-1], Zl[[1]])
```

Note: The list 'Zl' contains two sparse matrices, one for the 'from' node in 'pop1' and one for the 'to' node in 'pop2'. Each sparse matrix has 20 rows (for the 20 populations) and 48 columns (for the 48 links). Each column has a single value of '1' that indicates the 'from' or 'to' population of the corresponding link. The matrix 'ZZ' is again a sparse matrix that is the sum of the two sparse matrices in 'Zl'. Each column thus has two values of '1', one for the 'from' and one for the 'to' node.

Now we can fit an `lmer` model (linear mixed model; see Week 6 videos) to the data. 

```{r}
mod1 <- lme4::lFormula(logDc.km ~ solarinso + forest + ag + shrub + 
                       dev + (1|pop1), data = CSFdata, REML = TRUE)
```

At this point an error message appears: "Warning message: Some predictor variables are on very different scales: consider rescaling". 

Which variable is causing this problem? To check, get R to show you the first few rows of the dataset:

```{r}
head(CSFdata)
```

One of these variables is a lot larger than the others, but has a small range. This often happens with variables such as easting and can cause issues for model fit. The common solution is to z-transform (standardize) the data, which is conveniently done in R using the `scale` function.

Note: we could use the scale function without specifying the arguments 'center' or 'scale', as both are 'TRUE' by default. The argument 'center=TRUE' centers the variable by subtracting the mean, the 'scale=TRUE' argument rescales the variables to unit variance by dividing each value by the standard deviation. The resulting variable has a mean of zero and a standard deviation and variance of one. 

```{r}
solarinsoz <- scale(CSFdata$solarinso, center=TRUE, scale=TRUE)
```

We then can attach these data back to our dataframe and check to make sure this worked:

```{r}
CSFdata <- cbind(CSFdata, solarinsoz)
names(CSFdata)
```

If `solarinsoz` is there, you are good.

While we are at it, we will make sure that these variables do not have issues with multicollinearity.

Make a dataframe of just the variables to test (note, you cannot use factors here):

```{r}
CSF.df <- with(CSFdata, data.frame(solarinsoz, forest, dev, shrub, ag))
usdm::vif(CSF.df)
```

If you get an error that there is no package called 'usdm', use install.packages("usdm")

Numbers less than 10, or 3, or 4, depending on who you ask, are considered to not be collinear enough to affect model outcomes. So we are good to go here. What would happen if we added grass to this?

```{r}
usdm::vif(cbind(CSF.df, grass=CSFdata$grass))
```

**Question 1**:	Why would adding in the last land cover cause a high amount of collinearity? Consider how these data were calculated.

The variables 'forest', 'dev', 'shrub', 'ag' and 'grass' together cover almost all land cover types in the study area. Each is measured as percent area, and together, they make up 100% or close to 100% of the land cover types along each link. Thus if we know e.g. that all 'forest', 'dev', 'shrub' and 'ag' together cover 80% along a link, then it is a good bet that 'grass' will cover the remaining 20%. 

With such sets of compositional data, we need to omit one variable to avoid multi-collinearity (where a variable is a linear combination of other variables), even though the pairwise correlations may be low. For example, there the variable 'grass' showed relatively low correlations with the other variables:

```{r}
cor(CSF.df, CSFdata$grass)
```

### c) Fit all five models

Now we have to remake the modeling objects with our new and improved data frame, but referring to our z-transformed data (thanks to Martin Van Strien and Helene Wagner for the base model code):

```{r}
Zl <- lapply(c("pop1","pop2"), function(nm) 
  Matrix:::fac2sparse(CSFdata[[nm]], "d", drop=FALSE))
ZZ <- Reduce("+", Zl[-1], Zl[[1]])
```

Fit an lmer model to the data:

```{r}
mod_1 <- lme4::lFormula(logDc.km ~ solarinsoz + forest + ag + shrub + 
                        dev + (1|pop1), data = CSFdata, REML = TRUE)
```

In the fitted model replace Zt slot (matrix for the random effects generated with just pop1) with the ZZ matrix created above:

```{r}
mod_1$reTrms$Zt <- ZZ
```

Refit the model (this involves a few steps of optimization starting from the previously fitted model `mod_1`):

```{r}
dfun <- do.call(lme4::mkLmerDevfun, mod_1)
opt <- lme4::optimizeLmer(dfun)
mod1 <- lme4::mkMerMod(environment(dfun), opt, mod_1$reTrms, fr = mod_1$fr)
summary(mod1)
```

In this output, we focus on the estimates of fixed effects, which we will use later to examine the effect of each variable. Note that there are no p-values because of the nature of these models and the philosophy of the package writers. There are packages available that calculate these but the results may be misleading. 
This is the closest to a full model in our dataset (although our models are not completely nested), so we will take a look at the residuals:

```{r}
plot(mod1) 
```

Residuals are centered around zero and do not show large groupings or patterns, although there is some increase in variation at larger numbers (so the model is having a more difficult time predicting larger genetic distances per km). We will keep that in mind as we move on.

Next we will check to make sure the residuals are normally distributed. 

```{r}
hist(residuals(mod1)) 
```

This can also be done with the qqmath function in package lattice if you are more used to seeing qq plots. These residuals look okay so we will move on (but if this were a publication we would do a closer examination of the shape of the data at larger genetic distances). 

Now we will make a function (called MPLE) to fit the rest of our models, so that we are not typing the same code over and over (which causes errors and long code that is difficult to navigate or update):

```{r}
MLPE <- function(variables, data) {
  mod2 <- lme4::lFormula(variables, data = data, REML = TRUE)
  dfun <- do.call(lme4::mkLmerDevfun, mod2)
  opt <- lme4::optimizeLmer(dfun)
  mod_2 <- lme4::mkMerMod(environment(dfun), opt, mod2$reTrms,fr = mod2$fr)
  mod2$reTrms$Zt <- ZZ

# Refit the model
  dfun <- do.call(lme4::mkLmerDevfun, mod2)
  opt <- lme4::optimizeLmer(dfun)
  modelout <- lme4::mkMerMod(environment(dfun), opt, mod2$reTrms,fr = mod2$fr)
  return(modelout)
}
```

To use this function, we define variables (the model as we want it to run) and data (the object that contains our data).

```{r}
mod2 <- MLPE(logDc.km ~ forest + ag + shrub + dev + (1|pop1), CSFdata)
mod3 <- MLPE(logDc.km ~ ag + dev + (1|pop1), CSFdata)
mod4 <- MLPE(logDc.km ~ slope + shrub + dev + (1|pop1), CSFdata)
mod5 <- MLPE(logDc.km ~ soils + slope + solarinsoz + (1|pop1), CSFdata)
```

### d) Compare evidence for models

Note: package MuMIn will do this for you, but for this exercise it is useful to see all the pieces of what goes into your evaluation. 

In information theory, we use information criteria (AIC, BIC) to evaluate the relative distance of our hypothesis from truth. For more information, see Burnham and Anderson (2002).

Note: We use extractAIC here in package lme4, which refits the model using REML = FALSE rather than the function AIC, which reverts to a different package and provides the biased estimate from REML = TRUE.

```{r}
# Alternative code HW:
Models <- list(Full=mod1, Landcover=mod2, HumanFootprint=mod3, 
               EnergyConservation=mod4, Historical=mod5)
CSF.IC <- data.frame(extractAIC = sapply(Models, extractAIC)[2,],
                     BIC = sapply(Models, BIC)) 
CSF.IC
```

We now have some results, great!

Now we will work with these a bit. First, because we do not have an infinite number of samples, we will convert AIC to AICc (which adds a small-sample correction to AIC).

First, find the k parameters used in the model and add them to the table.

```{r}
CSF.IC <- data.frame(CSF.IC, k = sapply(Models, function(ls) attr(logLik(ls), "df")))
CSF.IC
```

**Question 2**:	How does k relate to the number of parameters in each model?

Now, calculate AICc and add it to the dataframe:

```{r}
CSF.IC$AICc <- CSF.IC$extractAIC + 2*CSF.IC$k*(CSF.IC$k+1)/(48-CSF.IC$k-1)
CSF.IC
```

### e) Calculate evidence weights

Next we calculate evidence weights for each model based on AICc and BIC. These can be interpreted as the probability that the model is the closest to truth in the candidate model set. 

Calculate model weights for AICc:

```{r}
AICcmin <- min(CSF.IC$AICc)
RL <- exp(-0.5*(CSF.IC$AICc - AICcmin))
sumRL <- sum(RL)
CSF.IC$AICcmin <- RL/sumRL
```

Calculate model weights for BIC:

```{r}
BICmin <- min(CSF.IC$BIC)
RL.B <- exp(-0.5*(CSF.IC$BIC - BICmin))
sumRL.B <- sum(RL.B)
CSF.IC$BICew <- RL.B/sumRL.B
round(CSF.IC,3)
```

**Question 3**:	What did using AICc (rather than AIC) do to inference from these results?

In the multi-model inference approach, we can look across all the models in the dataset and their evidence weights to better understand the system. Here we see that models 1 and 5 have very little evidence of being close to the truth, that models 2 and 4 have more, and that model 3 has the most evidence of being the closest to truth, although how much more evidence there is for model 3 over 2 and 4 depends on which criterion you are looking at. BIC imposes a larger penalty for additional parameters, so it has a larger distinction between these. Let's review what these models are:

1.	**Full model**: solarinso, forest, ag, shrub, dev
2.	**Landcover model**: ag, shrub, forest, and dev
3.	**Human footprint model**: ag, dev
4.	**Energy conservation model**: slope, shrub, dev
5.	**Historical model**: soils, slope, solarinso

### f) Confidence intervals for predictors based on single best model

According to Row et al. (2017), we can use the confidence interval from the variables in the models to identify those that are contributing to landscape resistance. Looking at models 2 and 3, we have some evidence that shrub and forest cover matter, but it's not as strong as the evidence for ag and development. Let's look at the parameter estimates to understand more.

```{r}
#summary(mod2)
summary(Models$Landcover)
```

Now we'll estimate the 95% confidence interval for these estimates:

```{r}
#confint(mod2, level = 0.95, method = "Wald")
confint(Models$Landcover, level = 0.95, method = "Wald")
```

In essence, we use the confidence intervals to assess whether we can differentiate the effect of each variable from zero (i.e. statistical significance). The confidence intervals that overlap 0 do not have as much evidence of being important to gene flow, based on simulations in Row et al. (2017). So in this case, there is only strong evidence that agriculture influences the rate of gene flow. Note that because the metric is genetic distance, negative values indicate more gene flow.

**Question 4**:	What evidence is there that shrub and forest matter to gene flow from these analyses? What about slope and shrub? Would you include them in a conclusion about landscape resistance in this system?

**Question 5**:  What evidence is there that development influences gene flow from these analyses? Would you include it in a conclusion about landscape resistance in this system?

**Question 6**:  We excluded grass from our models because of multicollinearity. How could we investigate the importance of this variable?

## 3. Your turn to test additional hypotheses!

Create your own (small) set of hypotheses to rank for evidence using the dataset provided. Modify the code above to complete the following steps: 

1.  Define your hypotheses.
2.  Calculate the VIF table for full model.
3.  Make a residual plot for full model.
4.  Create table of AICc and BIC weights.
5.  Create confidence intervals from models with high evidence weights.

What can you infer from your analysis about what influences gene flow of this species?

```{r message=FALSE, warning=TRUE, include=FALSE}
LandGenCourse::detachAllPackages()
```
