---
title: "Week 11: Detecting Adaptation"
author: "Brenna R. Forester"
date: "`r Sys.Date()`"
show_toc: true
output:
  knitr:::html_vignette:
    toc: yes
    fig_width: 4 
    fig_height: 3.5
vignette: >
  %\VignetteIndexEntry{Week 11: Detecting Adaptation}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
## 1. Overview of Worked Example

### a) Goals
This worked example will illustrate the use of two types of genotype-environment association analyses, one univariate and one multivariate. Specifically, you will learn:

* Strategies for screening and preparing predictor variables for different GEA analyses;
* How to run and interpret a Latent Factor Mixed Model (LFMM);
* One option for post-processing LFMM results using the genomic inflation factor (GIF) and false discovery rate (FDR) to correct for multiple tests;
* How to run and interpret Redundancy Analysis for GEA.

### b) Data set
We will reanalyze genomic data from 94 North American gray wolves (*Canis lupus*) sampled across Canada and Alaska (Schweizer et al., 2016). We are interested in understanding how wolves may be locally adapted to environmental conditions across their North American range.

The genetic data are individual-based, and are input as allele counts (i.e. 0/1/2) for each locus. In the interest of computational efficiency, we will use a randomly sampled subset of 10,000 single nucleotide polymorphism (SNP) markers from the full data set (which contains 42,587 SNPs).

In addition, we have eight environmental predictors that are ecologically relevant and are not highly correlated (|r| < 0.7). This is a reduced set of predictors from the 12 originally included by Schweizer et al. (2016).

### c) Required R libraries

Most required packages should have been installed already when you installed 'LandGenCourse'.

```{r packages global_options, include=TRUE, results="hide", message=FALSE, warning=FALSE}
library(LandGenCourse)
#library(vegan)    # Used to run PCA & RDA
```

The packages 'LEA' and 'qvalue' are available from the 'Bioconductor' repository. 
```{r message=FALSE, warning=TRUE}
if(!requireNamespace("qvalue", quietly = TRUE)) {  
  if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
  BiocManager::install("qvalue")
}

if(!requireNamespace("LEA", quietly = TRUE)) {  
  if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
  BiocManager::install("LEA")
}
#require(LEA)
#require(qvalue)
```

The following 'setup chunk' is used to set the root address of file paths to the folder 'output' in the project folder.

```{r setup}
if(!dir.exists(paste0(here::here(),"/output"))) dir.create(paste0(here::here(),"/output"))
knitr::opts_knit$set(root.dir = normalizePath(paste0(here::here(),"/output"))) 
```

## 2. Import and prepare the data

### a) Import the genetic data
I downloaded these data from the Schweizer et al. (2016) [Dryad repository](http://datadryad.org/resource/doi:10.5061/dryad.c9b25) and converted them from .tped to .raw format using plink (Purcell et al., 2007). Then, using the R package `adegenet` (Jombart 2008), I read in the .raw data and extracted the matrix of 94 individuals x 42,587 SNPs. Finally, I randomly sampled 10,000 columns (SNPs) from the full data set, which is what we will analyze in this worked example.

Note: The full data in .raw format are available in the Supplemental Information for Forester et al. (2018). If you want to analyze the full data set, use the `read.PLINK` call from `adegenet` to read the data into R.

```{r load}
gen <- read.csv(system.file("extdata", "wolf_geno_samp_10000.csv", 
                            package = "LandGenCourse"), row.names=1)
dim(gen)
```

We have 94 individuals (rows) genotyped at 10,000 SNPs (columns).

Both LFMM and RDA require complete data frames (i.e., no missing genetic data). For this example, we'll use a simple approach to imputing missing genotype values: we will impute using the most common genotype at each SNP across all individuals.

```{r NA}
sum(is.na(gen)) # 27,987 NAs in the matrix (~3% missing data)
gen.imp <- apply(gen, 2, function(x) replace(x, is.na(x), 
                 as.numeric(names(which.max(table(x))))))
sum(is.na(gen.imp)) # No NAs
```

We could also use this imputation approach within ecotypes (rather than across all individuals). Other promising imputation methods for species lacking a reference genome include: using ancestry values from `snmf` in the `LEA` package (Frichot & Francois 2015), using Random Forest (implemented for genomic data in the R package `grur`, Gosselin 2017), and the program LinkImpute (Money et al., 2015).


### b) Import the environmental data
The original data set comes with 12 predictors, but many of them are highly correlated, which can cause problems for regression-based methods like LFMM and RDA. I conducted variable reduction using the |0.7| "rule of thumb" (Dormann et al., 2013) and an ecological interpretation of the relevance of possible predictors. Can you double check the correlations among the variables?

For more information on the rationale for variable reduction, see the full [RDA vignette](http://popgen.nescent.org/2018-03-27_RDA_GEA.html). 

```{r, load.env}
env <- read.csv(system.file("extdata", "EnvironmentalData_8pred.csv", 
                            package = "LandGenCourse"))

# Look at the structure of the data frame:
str(env) 
# Make individual names characters (not factors):
env$individual <- as.character(env$individual) 

# Confirm that genotypes and environmental data are in the same order:
identical(rownames(gen.imp), env[,1]) 
```

Now we'll subset just the environmental predictors & shorten their names:

```{r, env.prep}
pred <- env[,5:12]
colnames(pred) <- c("AMT","MDR","sdT","AP","cvP","NDVI","Elev","Tree")
```

For the univariate LFMM test, we could run a separate set of tests for each of these eight predictors; this would be a test for each of the 10,000 SNPs with each predictor = 80,000 tests (!). Instead, for LFMM, we'll perform a PCA on the environmental predictors and use the first principal component (PC) as a synthetic predictor. This will reduce our ability to interpret the output, since the PC predictor will be a linear combination of the original eight variables, but it will reduce the number of corrections needed for multiple tests. Your decision of how to handle multiple predictors for a univarate GEA test will depend on the study goals and characteristics of the data set.

There are many ways to run PCA in R; we'll use the `rda` function in `vegan` (Oksanen et al., 2016). We'll center and scale the predictors (`scale=T`), since they're in different units. We'll then determine the proportion of the environmental variance explained by each PC axis & investigate how the original predictors correlate with the first PC axis.

```{r, PCA}
pred.pca <- vegan::rda(pred, scale=T)
summary(pred.pca)$cont
screeplot(pred.pca, main = "Screeplot - Eigenvalues")

# correlations between the PC axis and predictors:
round(vegan::scores(pred.pca, choices=1:8, display="species", scaling=0), digits=3)
```

40% of the variance in the predictors is explained by the first PC axis, and 23% by the second axis. We could follow up with an LFMM model using the second axis as a predictor, if we wanted. The strongest correlations with PC1 are annual mean temperature (AMT), tree cover (Tree), NDVI, and annual precipitation (AP).

We'll store our synthetic PC axis predictor as `pred.PC1` for use in LFMM.

```{r, PC1}
pred.PC1 <- vegan::scores(pred.pca, choices=1, 
                          display="sites", scaling=0)
```


## 3. Latent Factor Mixed Models (LFMM): a univariate GEA

LFMM is a univariate test, which means that it builds a model for each SNP and each predictor variable. In this case, we will build 10,000 SNPs x 1 synthetic predictor = 10,000 separate LFMM tests. Note that LFMM uses an MCMC algorithm, so detections will vary across runs (i.e., you will likely get slightly different results from those presented here).

### a) Determine K
LFMM requires an estimate of the number of populations in the data (K). To determine the most likely value of K, we'll use the function `snmf` in the LEA package. Functions in the LEA package require that we write files to a directory, so when you run this on your own computer, you'll want to set a temporary working directory.

For this assessment of K, we'll run only one replicate of `snmf` for each value of K. We'll test K values from 1 to 6 since there are 6 identified wolf ecotypes.

If you wanted to extract ancestry coefficients for the individual wolves, you'd want to run more replicates. See the [LEA package tutorial](http://membres-timc.imag.fr/Olivier.Francois/LEA/tutorial.htm) for details on snmf and additional tips for running LFMM.

```{r, snmf, results="hide"}
outfile <- file.path(here::here(), "output", "genotypes.geno")
LEA::write.geno(gen.imp, outfile)
findK <- NULL
findK <- LEA::snmf(outfile, K=1:6, ploidy=2, entropy=T, rep=1, project = "new")
#plot(findK)

#LEA::write.geno(gen.imp, "genotypes.geno")
#findK <- NULL
#findK <- LEA::snmf("genotypes.geno", 
#                   K=1:6, ploidy=2, entropy=T, rep=1, project = "new")
#plot(findK)
```

The most likely value of K is where minimal cross-entropy is lowest -- in this case, at K=3.

```{r, setK}
K <- 3
```

### b) Run LFMM

Again, we have to write out the inputs before running the model: 

```{r, LFMM, results="hide"}
write.table(gen.imp, file=file.path(here::here(), "output", "gen.lfmm"), 
            row.names=F, col.names=F)
write.table(pred.PC1, file=file.path(here::here(), "output","PC1.env"), 
            row.names=F, col.names=F)

```

Now let's run the model. For this worked example, we'll use fewer than the recommended number of repetitions, iterations, and burnin in the interest of time (if your computer is slow, you may want to reduce these further).

The following (commented out) line shows the recommended parameters:

```{r, LFMM1, results="hide"}
wolf.lfmm <- NULL

wolf.lfmm <- LEA::lfmm(
  input.file=file.path(here::here(), "output", "gen.lfmm"),
  environment.file=file.path(here::here(), "output", "PC1.env"), 
  K=K, project="new", repetitions=3, iterations=4000, burnin=2000)

#wolf.lfmm <- LEA::lfmm(
#  input.file=file.path(here::here(), "output", "gen.lfmm"), 
#  environment.file=file.path(here::here(), "output", "PC1.env"), 
#  K=K, project="new", repetitions=10, iterations=5000, burnin=2500)
```

### c) Identify LFMM candidates
Next, we post-process the model output. First we extract the z-scores and take the median across the replicate runs. 

```{r}
zs <- LEA::z.scores(wolf.lfmm, K=K, d=1)
zs.med <- apply(zs, MARGIN=1, median)
```

Then we calculate the genomic inflation factor (GIF), which gives us a sense for how well the model has accounted for population structure in the data.

```{r}
GIF <- median(zs.med^2)/qchisq(0.5, df = 1)
GIF
```

We are looking for a GIF of around 1. The slightly elevated GIF indicates that the test may be overly liberal in identifying candidate SNPs. If the GIF is less than one, the test may be too conservative. Changing the value of K influences the GIF, so additional tests using the "best" value of K +/- 1 may be needed in some cases. See Fran?ois et al. (2016) for more details. 

For now, we'll proceed with this slightly elevated GIF. The next step is to adjust the p-values using the GIF and plot them:

```{r}
adj.pv <- pchisq(zs.med^2/GIF, df = 1, lower = FALSE)
hist(adj.pv, main="Histogram of adjusted p-values")
```

We expect to see a relatively flat histogram (most loci not under selection) with a peak near zero, indicating candidate adaptive markers. For this data set, we also see a peak near one, which indicates that we have a large number of uninformative (for detecting selection) SNPs. One option in this case is to remove these SNPs (e.g., remove SNPs with p-values > 0.95) and rerun the analysis (O. Fran?ois, personal communication). In the interest of saving time, we won't do that here.

Finally, we convert the adjusted p-values to q-values using a false discovery rate (FDR) cutoff of 0.05 (again see Fran?ois et al. (2016) for more information).

```{r}
qv <- which(qvalue::qvalue(adj.pv, fdr=0.05)$signif)
# the names of the loci detected as candidates by lfmm:
cand.lfmm <- colnames(gen.imp)[qv]   
length(cand.lfmm)
```

LFMM identified a large number of candidate SNPs (around 800 out of 10,000), even after correcting for population structure. Remember that your detections (both number and SNPs detected) may differ, since LFMM uses an MCMC algorithm.


## 4. Redundancy Analysis (RDA): a multivariate GEA

### a) Run RDA

RDA is a multivariate ordination technique that can analyze many loci and environmental predictors simultaneously. For this reason, we can input all of the SNPs and environmental predictors at once, with no need to correct for multiple tests. RDA determines how groups of loci covary in response to the multivariate environment, and can better detect processes that result in weak, multilocus molecular signatures relative to univariate tests (Rellstab et al., 2015; Forester et al., 2018).

Note that RDA can also be used for population-based data, in which case you could input the genetic data as allele frequencies within demes.

The code to run the RDA is simple. However, we highly recommend reading Borcard et al. (2011) for details on the implementation and interpretation of RDA models and the objects created by `vegan`. RDA runs relatively quickly on most data sets, however on a very large data set (such as the full wolf data set) it can take 15-20 minutes, depending on the computer.

```{r, rda}
wolf.rda <- vegan::rda(gen.imp ~ ., data=pred, scale=T)
wolf.rda
```

First, note that we will have as many constrained ("RDA") axes as we have predictors in the model. All residual variance is then modeled by PCA (the unconstrained "PC" axes). The proportion of the variance explained by the environmental predictors is given under the "Proportion" column for "Constrained"; this is equivalent to the R^2^ of a multiple regression. Just like in multiple regression, this R^2^ will be biased and should be adjusted based on the number of predictors. We can calculate the adjusted R^2^ using:

```{r, R2}
vegan::RsquareAdj(wolf.rda)
```

Our constrained ordination explains about 5% of the variation; this low explanatory power is not surprising given that we expect that most of the SNPs in our dataset will not show a relationship with the environmental predictors (e.g., most SNPs will be neutral).

The eigenvalues for the constrained axes reflect the variance explained by each canonical axis:

```{r}
summary(wolf.rda)$concont
```

We can visualize this information using a screeplot of the canonical eigenvalues by calling `screeplot`:

```{r, screeplot, , fig.width=6.2, fig.height=4}
screeplot(wolf.rda)
```

Here, we can see that the first three constrained axes explain most of the variance. The screeplot provides an informal (and quick) way to determine how many constrained axes to include when we search for candidate SNPs (below). We could start by investigating RDA axes that explain the most variance (excluding those after the "drop off" point in the screeplot.) 

You can run a formal test of statistical significance of each constrained axis using:
`anova.cca(wolf.rda, by="axis")`. We can assess both the full model and each constrained axis using F-statistics (Legendre et al, 2010). The null hypothesis is that no linear relationship exists between the SNP data and the environmental predictors. See `?anova.cca` for more details and options.

The permutation process to test the signficiance of each axis takes a while (up to a few hours on large data sets), so we'll just use the screeplot for a first assessment. If we did run the formal test, we would find that the first three constrained axes are significant (p = 0.001); constrained axis 4 has a p-value of 0.080, while axes 5-8 have p-values > 0.850. This corresponds with our evaluation of the screeplot, above.

Finally, `vegan` has a simple function for checking Variance Inflation Factors for the predictor variables used in the model:

```{r, VIF}
vegan::vif.cca(wolf.rda)
```

All values are below 10, and most are below 5, which indicates that multicollinearity among these predictors shouldn't be a problem for the model. We could remove one of the temperature variables (AMT or MDR) if we were concerned about these higher VIF values (Zuur et al., 2010).

Let's make a quick plot of the RDA output using the default plotting in `vegan`: 

```{r, simple_plot, fig.width=4, fig.height=4, fig.show='hold'}
plot(wolf.rda, scaling=3)          # default is axes 1 and 2
plot(wolf.rda, choices = c(1,3), scaling=3)  # axes 1 and 3
```

Here, the SNPs are in red (in the center of each plot), and the individuals are the black circles. The blue vectors are the environmental predictors. The relative arrangement of these items in the ordination space reflects their relationship with the ordination axes, which are linear combinations of the predictor variables.

See the full [RDA vignette](http://popgen.nescent.org/2018-03-27_RDA_GEA.html) for details on how to make more informative (and prettier!) RDA plots for this data set. For example, we could more clearly visualize the identified candidate loci in the ordination space and see how they are linked to the environmental predictors. We could also use RDA to investigate how wolf ecotypes (based on individual genotypes) are distributed in relation to the environmental predictors (Forester et al., 2018, Figures 9 & 10).


### b) Identify RDA candidates

We'll use the loadings of the SNPs (their location) in the ordination space to determine which SNPs are candidates for local adaptation. The SNP loadings are stored as `species` in the RDA object. We'll extract the SNP loadings from the first three constrained axes:

```{r, loadings}
load.rda <- summary(wolf.rda)$species[,1:3]
```

If we look at histograms of the loadings on each RDA axis, we can see their (relatively normal) distribution. SNPs loading at the center of the distribution are not showing a relationship with the environmental predictors; those loading in the tails are, and are more likely to be under selection as a function of those predictors (or some other predictor correlated with them).

```{r, loadings_plot, fig.width=2.5, fig.height=2.5, fig.show='hold'}
hist(load.rda[,1], main="Loadings on RDA1")
hist(load.rda[,2], main="Loadings on RDA2")
hist(load.rda[,3], main="Loadings on RDA3") 
```

I've written a simple function to identify SNPs that load in the tails of these distributions. We'll start with a 3 standard deviation cutoff (two-tailed p-value = 0.0027). As with all cutoffs, this can be modified to reflect the goals of the analysis and our tolerance for true positives vs. false positives. For example, if you needed to be very conservative and only identify those loci under very strong selection (i.e., minimize false positive rates), you could increase the number of standard deviations to 3.5 (two-tailed p-value = 0.0005). This would also increase the false negative rate. If you were less concerned with false positives, and more concerned with identifying as many potential candidate loci as possible (including those that may be under weaker selection), you might choose a 2.5 standard deviation cutoff (two-tailed p-value = 0.012).

I define the function here as `outliers`, where `x` is the vector of loadings and `z` is the number of standard deviations to use:

```{r, outliers}
outliers <- function(x,z){
  # find loadings +/- z SD from mean loading:     
  lims <- mean(x) + c(-1, 1) * z * sd(x) 
  # locus names in these tails:
  x[x < lims[1] | x > lims[2]]           
}
```

Now let's apply it to the first three constrained axes:

```{r, candidates}
cand1 <- outliers(load.rda[,1],3) # 38
cand2 <- outliers(load.rda[,2],3) # 69
cand3 <- outliers(load.rda[,3],3) # 34

length(cand1)+length(cand2)+length(cand3)
```

We have 38 candidates on axis 1, 69 on axis 2, and 34 on axis 3, for a total of 141 candidate SNPs out of the 10,000 SNPs included in this analysis.

Let's make a single data frame with the axis, SNP name, & loading:

```{r, outliers_df1}
cand1 <- cbind.data.frame(rep(1,times=length(cand1)), names(cand1), unname(cand1))
cand2 <- cbind.data.frame(rep(2,times=length(cand2)), names(cand2), unname(cand2))
cand3 <- cbind.data.frame(rep(3,times=length(cand3)), names(cand3), unname(cand3))

colnames(cand1) <- colnames(cand2)<- colnames(cand3) <- c("axis","snp","loading")

cand.rda <- rbind(cand1, cand2, cand3)
cand.rda$snp <- as.character(cand.rda$snp)
```

Some of these may be duplicate detections; let's check:

```{r, detections}
# 7 duplicate detections:
length(cand.rda$snp[duplicated(cand.rda$snp)])
# 134 unique candidate SNPs:
cand.rda <- cand.rda[!duplicated(cand.rda$snp),] 
# duplicates were on axis 2:
table(cand.rda$axis)                             
```

Let's see what environmental predictors are most strongly correlated with the first three RDA axes:

```{r, env.axes}
vegan::intersetcor(wolf.rda)[,1:3]
```

Generally, candidate SNPs on axis 1 represent multilocus sets of SNP genotypes associated most strongly with annual mean temperature and annual precipitation; SNPs on axis 2 represent genotypes associated with mean diurnal range; and SNPs on axis 3 represent genotypes associated with precipitation seasonality. See the full [RDA vignette](http://popgen.nescent.org/2018-03-27_RDA_GEA.html) for additional investigation of candidate SNPs. 


## 5. Compare LFMM and RDA candidates

Let's see what kind of overlap we have in our candidates from the two methods. Remember that we had ~800 candidates for LFMM and 134 candidates for RDA.

```{r, overlap}
overlap <- cand.rda$snp[cand.rda$snp %in% cand.lfmm]
length(overlap)
```

We had relatively few detections in common across the two methods. What does this mean for those detections? And what does it mean for the LFMM and RDA detections that are not in common? Things to consider include the differences in the statistical approaches (univariate vs. multivariate) and corrections (or lack of) for population structure.


## 6. References

Borcard D, Gillet F, Legendre P (2011) [*Numerical Ecology with R*](http://www.springer.com/us/book/9781441979759). Springer, New York.

Dormann CF, Elith J, Bacher S, et al. (2013) [Collinearity: a review of methods to deal with it and a simulation study evaluating their performance](http://onlinelibrary.wiley.com/doi/10.1111/j.1600-0587.2012.07348.x/abstract). *Ecography*, 36: 27-46.

Forester BR, Lasky JR, Wagner HH, Urban DL (2018) [Comparing methods for detecting multilocus adaptation with multivariate genotype-environment associations](https://www.biorxiv.org/content/early/2017/12/17/129460). *Molecular Ecology*.

Forester BR (2018) [Vignette: Detectingn multilocus adaptation using Redundancy Analysis (RDA)](http://popgen.nescent.org/2018-03-27_RDA_GEA.html). Population Genetics in R: [popgen.nescent.org](http://popgen.nescent.org/).

Fran?ois O, Martins H, Caye, K, Schoville S (2016) [Controlling false discoveries in genome scans for selection](http://onlinelibrary.wiley.com/doi/10.1111/mec.13513/full). *Molecular Ecology*, 25: 454-469.

Frichot E, Fran?ois O (2015) [LEA: An R package for landscape and ecological association studies](http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12382/abstract). *Methods in Ecology and Evolution*, 6: 925-929.

Gosselin T (2017) [grur: an R package tailored for RADseq data imputations](https://github.com/thierrygosselin/grur). R package version 0.0.1 doi:10.5281/zenodo.496176.

Jombart, T (2008) [adegenet: a R package for the multivariate analysis of genetic markers](https://academic.oup.com/bioinformatics/article/24/11/1403/191127). *Bioinformatics*, 24: 1403-1405.

Legendre P, Oksanen J, ter Braak CJ (2010) [Testing the significance of canonical axes in redundancy analysis](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/j.2041-210X.2010.00078.x). *Methods in Ecology and Evolution*, 2: 269-277.

Money D, Migicovsky Z, Gardner K, Myles S (2017) [LinkImputeR: user-guided genotype calling and imputation for non-model organisms](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-017-3873-5). *BMC Genomics*, 18: 1-12.

Oksanen J, Blanchet FG, Kindt R, et al. (2016) [*vegan: Community Ecology Package*](https://CRAN.R-project.org/package=vegan). R package version 2.3-5.

Rellstab C, Gugerli F, Eckert AJ, Hancock AM, Holderegger R (2015) [A practical guide to environmental association analysis in landscape genomics](http://onlinelibrary.wiley.com/doi/10.1111/mec.13322/abstract). *Molecular Ecology*, 24: 4348-4370.

Schweizer RM, vonHoldt BM, Harrigan R, et al. (2016) [Genetic subdivision and candidate genes under selection in North American grey wolves](http://onlinelibrary.wiley.com/doi/10.1111/mec.13364/full). *Molecular Ecology*, 25: 380-402.

Zuur AF, Ieno EN, Elphick CS (2010) [A protocol for data exploration to avoid common statistical problems](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/j.2041-210X.2009.00001.x). *Methods in Ecology and Evolution*, 1: 3-14.

```{r message=FALSE, warning=TRUE, include=FALSE}
#LandGenCourse::detachAllPackages()
```
