---
title: "Week 13: Gravity Models"
author: "Melanie Murphy"
date: "`r Sys.Date()`"
show_toc: true
output:
  knitr:::html_vignette:
    toc: yes
    fig_width: 4 
    fig_height: 3.5
vignette: >
  %\VignetteIndexEntry{Week 13: Gravity Models}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
## 1. Overview of Worked Example

### a) Background

There are many ways graphs can be implemented to understand population structure and relate that structure to landscape characteristics (see Dyer and Nason 2004). In this exercise, we will calculate various graph metrics and apply graphs to fit a gravity model.  

Gravity models are a type of inferential model that exploit graph characteristics. Gravity models include both at-site and between-site landscape data. They are a type of graph consisting of nodes and edges. These nodes and edges of landscape characteristics associated with these graph elements.

### b) Data set

In this exercise, you will use the gravity model framework to build an empirical model of gene flow for the Columbia spotted frog dataset in central Idaho that you have used for several other exercises (Murphy et al. 2010).


### c) Required R libraries

All required packages have already been installed with LandGenCourse.

```{r packages global_options, include=TRUE, results="hide", message=FALSE, warning=FALSE}
library(LandGenCourse)
library(sp)
#library(landscapemetrics)
#library(raster)
#library(rgdal)
#library(GeNetIt)
#library(spatialEco)
#library(GeNetIt)
#library(igraph)
#library(deldir)
```


#### Set working and data directories  - NEEDS TO BE REMOVED  
#wd = "C:/R/spatialR/day3/session6" # set your working directory here
#setwd(wd)
#ddir = file.path("C:/R/spatialR/day3", "data", "S6")


## 2. Calculating graph metrics

### a) Read in, make a spatial object and plot wetlands (Wetlands.csv).  

Read in the wetland csv file. 
```{r}
wetlands <- read.csv(system.file("extdata", "Wetlands.csv", 
                            package = "LandGenCourse"), header = TRUE) 
str(wetlands)
```

Coerce to a SpatialPointsDataFrame and look at the structure of the related dataframe.  
```{r}
sp::coordinates(wetlands) <- ~X+Y
class(wetlands)
str(wetlands)
```

Plot the wetlands
```{r}
plot(wetlands, asp=1, bty="n", xlab="", ylab="", main = "All Wetlands")
  points(wetlands, pch=19, cex=0.75, col="blue")
```

### b) Create a graph from the wetlands 

We'll create a graph that could represent connectivity using Delaunay triangulation, then plot the result.  

Delaunay triangulation, create delaunay graph
```{r}
options(warn=-1)
wetlandgraph <- deldir::deldir(coordinates(wetlands)[,1], 
                       coordinates(wetlands)[,2], 
                       z = wetlands$SiteName) 
options(warn=0)
```

Plot the graph with the wetlands
```{r}
plot(wetlands, asp=1, bty="n", xlab="", ylab="", main = "All Wetlands")
  points(wetlands, pch=19, cex=0.75, col="blue")
plot(wetlandgraph, wlines = "triang", wpoints="none",
     number=FALSE, add=TRUE, lty=1) 
```

**Questions:**

- What other types of graphs could you build?  
- Can you build a different graph and use this graph in your analysis?

### c) Create adjacency matrix

What wetlands are connected to each other based on the Delaunay triangulation? Create an adjacency matrix from the graph object and make an adjacency matrix. 

```{r}
ind <- wetlandgraph$delsgs[,5:6] #pull out individual nodes
adj <- matrix(0, length(wetlands$X), length(wetlands$Y)) 
  for (i in 1:nrow(ind)){ 
    adj[ind[i,1], ind[i,2]] <- 1 
    adj[ind[i,2], ind[i,1]] <- 1 
  } 
```

### d) Calculate graph metrics

This graph, if it is ecologically meaningful  contains information in the graph structure itself. Calculate graph metrics of degree and betweenness.  


**Questions:**

- In what way(s) is the resulting graph potentially ecologically meaningful?  
- How might it not be ecologically or biologically meaningful?

Make an igraph network from the matrix we just made
```{r}
wetnet <- igraph::graph_from_adjacency_matrix(adj, weighted = NULL, mode="undirected") 
plot(wetnet)
```


### e) Add graph metrics to data.frame

Calculate degree- the number of connections a node has  

```{r}
wetlands@data$degree <- igraph::degree(wetnet)
head(wetlands@data)
```

Calculate betweenness- the number of shortest paths going through a node
```{r}
wetlands@data$betweenness <- igraph::betweenness(wetnet) 
head(wetlands@data)
```

**Challenge:**

- Can you code your own degree or betweenness centrality function?

## 3. Combine frog data with graph metrics

### a) Add graph node data to frog site data

Using the RALU_Site data, read in the data, add the node data (betweenness and degree) and create a shape file that includes the node data. This process will mirror part 1.  

**Questions:** Look at the RALU_Site file.  

- What are the fields here?  
- What data are included?  

Import site data
```{r}
sites <- read.csv(system.file("extdata", "RALU_Site.csv", 
                            package = "LandGenCourse"), header = TRUE) 
head(sites)
```

Extract degree and betweenness from graph data
```{r}
nodestats <- as.data.frame(wetlands@data[,3:5])
degree.betweenness <- nodestats[which(nodestats$SiteName %in% sites$SiteName),]
head(degree.betweenness)
```

Add to site data
```{r}
sites <- merge(degree.betweenness, sites, by= "SiteName" )
head(sites)
```

Note: Using names is dangerous as, small changes in names can result in non-matches. In this case, the ID fields are not consistent (data were collected at different times for different purposes originally). However, names are standardized in a drop-down list of a database. So they are a matching field. My preference is do to this type of operation on a numeric field.  
```{r}
coordinates(sites) <- ~X+Y
str(sites)
```

### b) Check data types

Get data as proper type. Are all of the data fields reading as the correct type?

```{r}
summary(sites@data)
sites@data$SiteName <- as.character(sites@data$SiteName)
class(sites@data$SiteName)
```

```{r}
sites@data$SiteID <- as.factor(sites@data$SiteID)
class(sites@data$SiteID)
```

## 4. Merge graph with genetic distance data

Create graph from site locations and merge with genetic distance data.

### a) Build graph from occupied sites

To assess connectivity using a gravity model, we need to build a graph from the occupied frog sites. This could be any type of graph, but I generally use saturated or pruned by some maximum distance.
  

Note: make sure to use correct field here:
```{r}
dist.graph <- GeNetIt::knn.graph(sites, row.names = sites@data[,"SiteID"])
#dist.graph@proj4string@projargs <- "+proj=utm +zone=11 +ellps=GRS80 +towgs84=0,0,0,-0,-0,-0,0 +units=m +no_defs "
#dist.graph <- GeNetIt::knn.graph(sites, row.names = sites@data[,"SiteName"], max.dist=5000)
```

The "k greater than one-third of the number of data points" is a warning issued by the k nearest neighbor function.  In our case, this is not a problem as we want a graph that k is equal to 1-n, that is a saturated graph.

### b) Merge graph with genetic distance

This involves: reading in RALU_Dps genetic distance. Read in genetic distance file (RALU_Dps), convert to flow (1-distance) and unfold into a dataframe. Then merge graph with genetic distances.

Read in the genetic distance matrix
```{r}
gdist <- read.csv(system.file("extdata", "RALU_Dps.csv", 
                            package = "LandGenCourse"), header=TRUE)
rownames(gdist) <- t(names(gdist))
gdist <- as.matrix (gdist)
head(gdist)
```

Convert genetic distance to flow
```{r}
gdist <- GeNetIt::flow(gdist)
head(gdist)
```

Convert genetid "flow" matrix into an unfolded dataframe with site IDs
```{r}
gdist <- GeNetIt::dmatrix.df(gdist)
head(gdist)
```

The default column name is "distance" as this matrix could represent multiple type of distances. We are renaming here to avoid confusion as to the type of distance here.  
```{r}
names(gdist)[3] <- "GDIST"
names(gdist)
```

Some housekeeping here to rename colums to from, to nodes and remove "X"s added in conversion from matrix.
```{r}
names(gdist)[1] <- "FROM"
names(gdist)[2] <- "TO"
gdist[,1] <-sub("X", "", gdist[,1])
gdist[,2] <-sub("X", "", gdist[,2])
names(gdist)
```

Create an identifier of to from nodes to connect back to the graph and link gdist data to knn graph.
```{r}
gdist <- cbind(from.to=paste(gdist[,1], gdist[,2], sep="."), gdist)
dist.graph@data$from.to <- paste(dist.graph$from_ID, dist.graph$to_ID, sep=".")
dist.graph <- merge(dist.graph, gdist, by = "from.to") 
head(dist.graph@data)
```

### c) Write out results (ASCII csv and lines shapefile).

Saving the results (as ASCII csv and lines shapefile) is is a really useful operation for your own data, especially if you have a large graph, so you don't have to recreate this object.  

```{r}
if(!dir.exists(paste0(here::here(),"/output"))) 
  dir.create(paste0(here::here(),"/output"))
write.csv(gdist, file= paste0(here::here(),"/output/gdist.csv"))
```

Uncheck the following lines to write out a shapefile. This is commented out as rgdal may not work properly, depending on your computer configuration.
```{r}
#rgdal::writeOGR(dist.graph, paste0(here::here(),"/output"), "DistGraph", 
#                driver="ESRI Shapefile", check_exists=TRUE, overwrite_layer=TRUE)
```

## 5. Preparing raster-based covariates 

### a) Import raster data as stack 

This function will import a raster stack with nine raster maps of the study area.
```{r}
xvars <- rio::import("https://www.dropbox.com/s/xjl9zpgqplwg1us/ralu.rasters.rds?dl=1")
xvars
names(xvars)
```

### b) Calculate wetland area within buffer

You want to know if areas of dense wetlands produce more frogs. Calculate the proportion of the landscape around each site that is wetland. What buffer distance will you use?

We can create a wetland raster from the NLCD data. Wetland classes are 11 (open water), 90 and 95.

Create a vector of reclassification where non-wetland is a 0, wetland is a 1.
```{r}
m <- c(0,10.8, 0,10.9,12.1,1,12.9,89.1,0, 89.5,95.1,1)
  reclass <- matrix(m, ncol=3, byrow=TRUE)
```

Reclassifying nlcd by the reclass matrix
```{r warning=FALSE}
wetlnd <- raster::reclassify(xvars$nlcd, reclass) 
```

```{r warning=FALSE}
  wetlnd@data@names <- "wetlnd"
```

```{r}
plot(wetlnd)
```

Adding this new parameter to our raster stack
```{r}
xvars <- raster::stack(xvars, wetlnd)
names(xvars)
```

### c) Create raster of wetland proportion 

Create a raster of the proportion of landscape (PLAND) that is wetland, using a 300 m radius. 

**Challenge**: 

- What happens if you change this radius?  
- What radius do you think makes the most sense ecologically?

Here we adapt code from Week 2 Worked Example.

```{r}
nlcd_sampled <- landscapemetrics::sample_lsm(landscape = xvars[["wetlnd"]], 
                                                   what = "lsm_c_pland",
                                                   shape = "circle",
                                                   y = sites, 
                                                   size = 300, 
                                                   return_raster = FALSE,
                                                   plot_id=sites@data$SiteID)
pwetland <- dplyr::select(dplyr::filter(nlcd_sampled, class == 1, 
                                        metric == "pland"), plot_id, value)  
names(pwetland) <- c("SiteID", "pwetland")
pwetland$pwetland <- pwetland$pwetland/100
head(pwetland)
```

Important: there could be cases with no wetlands (where prop.landscape should be zero), which will result in missing rows in `pwetland`. Here we use `left_join` to join rows withi `sites` by `SiteID`, then replace missing values by 0.

```{r}
sites@data <- dplyr::left_join(sites@data, pwetland)
sites@data$pwetland[is.na(sites@data$pwetland)] <- 0
head(sites@data)
```

**Challenge:** 

- Try creating some additional metrics of your own from these rasters.  

## 6. Extract raster stats for nodes and edges 

### a) Extract at-site variables from rasters

Add characteristics of sample sites from your rasters as potential at site variables.  Here we are extracting the raster values that intersect our wetlands (point data).  What raster is not included in this step?  Why?  What at-site characteristics may impact the production of potential migrants?

```{r}
sites@data <- data.frame(sites@data, raster::extract(xvars, sites))
```
```{r}
names(sites@data)
```
### b) Add covariates to graph edges.  

Calculating statistical moments (e.g., mean, sdev) for categorical variables makes no sense. We we will remove them here.  

```{r}
idx <- which(names(xvars) %in% c("nlcd","wetlnd"))
```

### c) Calculating stats along edges
Here we define the projection of the distance graph and then calculate statistics

You can calculate any statistical moment you wish from your sample of the landscape between nodes. Make sure that these moments are ecologically/biologically meaningful.

```{r}
dist.graph@proj4string@projargs <- "+proj=utm +zone=11 +ellps=GRS80 +towgs84=0,0,0,-0,-0,-0,0 +units=m +no_defs "

stats <- GeNetIt::graph.statistics(dist.graph, r = xvars[[-idx]], buffer= NULL, 
						  stats = c("min", "mean", "max", "var", "median"))
dist.graph@data <- data.frame(dist.graph@data, stats)
names(dist.graph@data)
```


**Bonus challenge:**

- Create a function for returning the 95th percentile. 
- How would you create this function and add it to the stats calculated?
- What other statistical moments do you want?  
- Can you create a function?

### d) Calculating stats for categorical variables

What about categorical variables?  Moments are nonsensical. 

- Create a function for returning the % wetland between sites. 
- IMPORTANT:  We do not want these values to be correlated with distance, so don't count number pixels.  
- Then use this function to calculate an additional statistic, and then add it to the graph.
- Are there other categorical variables that you think may be ecologically important?

```{r}
wet.pct <- function(x) { 
  x <- ifelse( x == 11 | x == 90 | x == 95, 1, 0)
    prop.table(table(x))[2] 
}
```

```{r}
wetstats <- GeNetIt::graph.statistics(dist.graph, r=xvars$nlcd, buffer= NULL, 
						stats = c("wet.pct"))
  wetstats[is.na(wetstats)] <- 0
  dist.graph@data <- data.frame(dist.graph@data, wetstats)
  names(dist.graph@data)
```
   
**Question:**

- What other categorical variables would you like to include in the analysis?  Can you create a function for these variables?
  
  
### e) Add node data to graph  

First create a list of names for the node data

```{r}
node.var <- c("degree", "betweenness", "Elev", "Length", "Area", "Perim", 
              "Depth", "pH","Dforest","Drock", "Dshrub", "pwetland", "cti",
			  "dd5", "ffp","gsp","pratio","hli","rough27","srr")
```

These are all at site variables. Remember that we pulled all raster varibles. We want to critically think about hypotheses and not use all of these parameters. 

- degree - graph degree
- betweenness - graph betweeness
- Elev - elevation (see comments below)
- Length - geographic distance
- Area - wetland area (field)
- Perim - wetland perimeter (field)
- Depth - wetland depth (field)- highly correlated with predatory fish presence/abundance
- pH - wetland pH (field)
- Dforest - distance to forest (field)
- Drock - distance to rock (field)
- Dshrub - distance to shrub (field)
- pwetland - proportion of wetland in X buffer (calculated above)
- cti - compound topographic wetness index - steady-state measure of wetness based on topography (raster data)
- dd5 - degree days >5 C (sum of temp) - (raster data)
- ffp - frost free period (raster data)
- gsp - growing season precipitation (raster data)
- pratio - ratio of growing season precip to annual precip (raster data) - can indicate amount of snow to rain
- hli - heat load index  - topographic measure of exposure, related to productivity (ice-off and primary productivity) in this system (raster data)
- rough27 - unscale topographic variation at a 27 X 27 (cells) window size (raster data)
- ssr - measure of topographic variation at a 27X27 (cells) windo size - for this system pulling out ridgelines (raster data)

NOTE: we are adding elevation here as a covariate.  HOWEVER - elevation does not represent 
ecological processes in and of itself.  I strongly encourage using the components (temp, moisture, rainfall, vegetation, accessibility, etc.) directly and not elevation as a surrogate parameter. 

Add the node data.  Remember that we will calculate the value for both the from node and the to node.  in a singly constained model, we will only use one of these (constrain ("group") by from (produciton) or to (attraction))

```{r}
node <- GeNetIt::build.node.data(sites@data, group.ids = "SiteID", from.parms = node.var)
head(node)
```

## 7. Gravity Models 

Now we get to create gravity models!

### a) Merge distance and site data

Merge edge (distance graph) and edge (site) data.
```{r}
gdata <- merge(dist.graph, node, by.x="from_ID", by.y="SiteID") 
  gdata <- gdata@data
  names(gdata)
```

### b) Define a set of models

Think about hypothesis and create a set of models.  What type of constraint? Write out model statements.  HOWEVER, need to check for correlations (#3) before settling on a final set of model. At this point, make a list of these models in a text editor, but do not run these models until you check correlations.
  

### c) Check for correlations  

You will need to do nodes and edges separately, remember that data have to be ln transformed. For zero values, a common approach is ln(x - (min(x) - 1))

```{r}
nodeln <- node[,c(2:21)]
  for(i in 1:ncol(nodeln)) {
    nodeln[,i] <- log(nodeln[,i] - (min(nodeln[,i]) - 1))
  }
nodecor.ln <- cor(nodeln, y = NULL, 
                  use = "complete.obs", 
                  method = "pearson")
round(nodecor.ln, 3) 
#pairs(nodecor.ln, pch=19, cex=0.50) 
```

```{r fig.height=5, fig.width=8}
edge.ln <- dist.graph@data[,10:length(dist.graph@data)]
  for(i in 1:ncol(edge.ln)) {
    edge.ln[,i] <- log(edge.ln[,i] - (min(edge.ln[,i]) - 1))
  }
edgecor.ln <- cor(edge.ln, y = NULL, 
                  use = "complete.obs", 
                  method = "pearson")
round(edgecor.ln, 3) 
```

### c) Write out resultss

Figure as pdf file:
```{r}
pdf(file=paste0(here::here(),"/output/node.cor.pdf"), width=20, height=20)
   pairs(nodecor.ln, pch=19, cex=0.50)
dev.off()
```

Correlation data:
```{r}
write.csv(round(edgecor.ln, 4), 
          file = paste0(here::here(),"/output/EdgeCorrelationsLn.csv"))
write.csv(round(nodecor.ln, 4), 
          file = paste0(here::here(),"/output/NodeCorrelationsLn.csv"))
```

### e) Compare models

Run and compare models representing your hypotheses.  Remember - we compete models using ML but use REML for final fit. Also remember that the null model contains distance (and all models must contain distance).

Null model:
```{r}
( null <- GeNetIt::gravity(y = "GDIST", x = c("length"), d = "length", group = "from_ID", 
                  data = gdata, method = "ML") )
```

Global model (this was based on my hypotheses):
```{r}
  ( global <- GeNetIt::gravity(y = "GDIST", x = c("length", "wet.pct.nlcd", 
                                         "median.gsp", "from.Depth", 
                                         "from.ffp", "from.hli", "from.pratio", 
                                         "from.degree", "from.betweenness", 
                                         "from.pwetland", "median.srr", 
                                         "median.rough27"), d = "length", 
                      group = "from_ID", data = gdata, method = "ML") )
```

Published model:
```{r}
( published <- GeNetIt::gravity(y = "GDIST", x = c("length", "median.gsp", "from.Depth", 
                    "from.hli", "median.cti", "median.srr"), d = "length", 
				     group = "from_ID", data = gdata, method = "ML"))
```

Habitat hypothesis
```{r}
( habitat <- GeNetIt::gravity(y = "GDIST", x = c("length", "wet.pct.nlcd", "median.gsp"), d = "length", 
                     group = "from_ID", data = gdata, method = "ML") )

```                     

Compare models: these are the names of the hypotheses (models) I tested.
```{r}
#compare.models(null, depth, product, climate, wetlands, topo, habitat, global)
#compare.models(depth, product, climate, wetlands, topo, habitat, published, global, null) 
GeNetIt::compare.models(null, habitat, global, published) #NOTE - global will need to be edited to match your paramters
```


 
### f) Diagnostic plots

```{r}
par(mfrow=c(2,3))
   for (i in 1:6) { plot(global, type=i) } 
```

### g) Fit final model(s)

Habitat:
```{r}
habitat_fit <- GeNetIt::gravity(y = "GDIST", x = c("length", "wet.pct.nlcd", "median.gsp"), 
                       d = "length", group = "from_ID", data = gdata, method = "REML")
```

Global:
```{r}
global_fit <- GeNetIt::gravity(y = "GDIST", x = c("length", "wet.pct.nlcd", "median.gsp", 
                                         "from.Depth", "from.ffp", "from.hli", 
                                         "from.pratio", "from.degree",  
                                         "from.betweenness", "from.pwetland", "median.srr", 
                                         "median.rough27"), 
                      d = "length", group = "from_ID", data = gdata, method = "REML")
```

Published:
```{r}
published_fit <- GeNetIt::gravity(y = "GDIST", x = c("length", "median.gsp", "from.Depth", 
                    "from.hli", "median.cti", "median.srr"), d = "length", 
				     group = "from_ID", data = gdata, method = "REML") 
```

Compare models
```{r}
GeNetIt::compare.models(global_fit, habitat_fit, published_fit)
```
					  
### h) Effect size

This effect size is NOT backwards transformed.  We are working on effect sizes for backwards transformed data.

```{r}
GeNetIt::gravity.es(habitat_fit)
GeNetIt::gravity.es(global_fit)
GeNetIt::gravity.es(published_fit)
```

**Question:** What did you learn?

- About Columbia spotted frogs in central Idaho?
- About linking genetic and landscape data with graphs and gravity models?
- About R programming?
